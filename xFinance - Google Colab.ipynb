{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-bigquery"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9_H7NP-NQmwm",
        "outputId": "639146bb-9bfd-40a3-8df1-44702133f63b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.21.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.7.0)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (24.1)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.31.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.63.1)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (3.20.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.6.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-auth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1IO_gFKbRVXM",
        "outputId": "80a4cc74-addd-4e2b-bbd0-5494ab83e08c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa as bibliotecas necessárias\n",
        "import requests  # Biblioteca para fazer requisições HTTP\n",
        "import pandas as pd  # Biblioteca para manipulação de dados\n",
        "from datetime import datetime, timedelta  # Bibliotecas para manipulação de datas\n",
        "import json  # Biblioteca para manipulação de dados em formato JSON\n",
        "from google.cloud import bigquery  # Biblioteca do Google Cloud para manipulação do BigQuery\n",
        "from google.colab import auth"
      ],
      "metadata": {
        "id": "PMrQqcOyQifH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "qvpvFZIXROJz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para chamar a API MyFinance\n",
        "def chamar_api_myfinance(url, headers, constraints=None):\n",
        "    print(\"Chamando API MyFinance...\")\n",
        "    lista_dados_todas_paginas = []  # Lista para armazenar os dados de todas as páginas\n",
        "    cursor = 0  # Inicializa o cursor para paginação\n",
        "    params = {\"cursor\": cursor}  # Define os parâmetros da requisição\n",
        "    if constraints:\n",
        "        params[\"constraints\"] = json.dumps(constraints)  # Adiciona as restrições aos parâmetros\n",
        "\n",
        "    while True:\n",
        "        # Faz a requisição à API\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        # Converte a resposta para JSON\n",
        "        response_ajustado_json = response.json()\n",
        "        # Obtém a parte \"response\" do JSON\n",
        "        dados_response = response_ajustado_json.get(\"response\", None)\n",
        "\n",
        "        if dados_response is not None:\n",
        "            # Obtém os resultados da resposta\n",
        "            results = dados_response.get('results', [])\n",
        "            # Obtém a quantidade restante de dados a serem buscados\n",
        "            remaining = dados_response.get('remaining', 0)\n",
        "            # Adiciona os resultados à lista\n",
        "            lista_dados_todas_paginas.extend(results)\n",
        "\n",
        "            if remaining <= 0:\n",
        "                break  # Encerra o loop se não há mais dados a buscar\n",
        "            else:\n",
        "                cursor += 100  # Atualiza o cursor para a próxima página\n",
        "                params[\"cursor\"] = cursor\n",
        "        else:\n",
        "            break  # Encerra o loop se não há dados na resposta\n",
        "\n",
        "    # Retorna os dados como um DataFrame do Pandas\n",
        "    return pd.DataFrame(lista_dados_todas_paginas)"
      ],
      "metadata": {
        "id": "uIrZFO0VQl_b"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para atualizar dados dos últimos dois dias\n",
        "def atualizar_dados_ultimos_dois_dias(url, headers):\n",
        "    dois_dias_atras = (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d')\n",
        "    constraints = [{\"key\": \"estimated_date\", \"constraint_type\": \"greater than\", \"value\": dois_dias_atras}]\n",
        "    df_incremental = chamar_api_myfinance(url, headers, constraints)\n",
        "    return df_incremental"
      ],
      "metadata": {
        "id": "unX8krLBQitL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para carregar todos os dados\n",
        "def carregar_todos_os_dados(url, headers):\n",
        "    df_inicial = chamar_api_myfinance(url, headers)\n",
        "    return df_inicial"
      ],
      "metadata": {
        "id": "of7qbwPSQivk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função principal que coordena a execução do script\n",
        "def main(request=None):\n",
        "    print(\"Iniciando execução do script...\")\n",
        "    # Obtém IDs do projeto a partir das variáveis de ambiente\n",
        "    #project_id = os.getenv(\"GCP_PROJECT_ID\")\n",
        "    project_id = \"youtube-xfinance\"\n",
        "    dataset_id = \"xfinance_dataset\"\n",
        "    table_name = \"transactions\"\n",
        "\n",
        "    # Cria um cliente do BigQuery utilizando as credenciais padrão do ambiente\n",
        "    client = bigquery.Client(project=project_id)\n",
        "    print(\"Conectado ao serviço BigQuery.\")\n",
        "\n",
        "    dataset_full_id = f\"{client.project}.{dataset_id}\"\n",
        "    dataset = bigquery.Dataset(dataset_full_id)\n",
        "    dataset.location = \"US\"\n",
        "\n",
        "    try:\n",
        "        # Verifica se o dataset existe\n",
        "        client.get_dataset(dataset)\n",
        "        print(f\"Dataset {dataset_id} já existe.\")\n",
        "    except:\n",
        "        # Cria o dataset se não existir\n",
        "        dataset = client.create_dataset(dataset, timeout=30)\n",
        "        print(f\"Dataset {dataset_id} criado com sucesso.\")\n",
        "\n",
        "    table_id = f\"{client.project}.{dataset_id}.{table_name}\"\n",
        "\n",
        "    url = \"https://myfin-financial-management.bubbleapps.io/api/1.1/obj/transactions\"\n",
        "    token = \"c612a092017fc39036d10905bf6ce586\"\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "\n",
        "    try:\n",
        "        # Verifica se a tabela existe\n",
        "        table = client.get_table(table_id)\n",
        "        table_exists = True\n",
        "        print(f\"Tabela {table_id} encontrada.\")\n",
        "    except:\n",
        "        table_exists = False\n",
        "        print(f\"Tabela {table_id} não encontrada, será criada.\")\n",
        "\n",
        "    if table_exists:\n",
        "        # Verifique se a tabela tem dados\n",
        "        query = f\"SELECT COUNT(*) as total_rows FROM `{table_id}`\"\n",
        "        query_job = client.query(query)\n",
        "        results = query_job.result()\n",
        "        total_rows = [row.total_rows for row in results][0]\n",
        "\n",
        "        if total_rows > 0:\n",
        "            # Atualização incremental\n",
        "            query = f\"SELECT MAX(`Modified Date`) as last_update FROM `{table_id}`\"\n",
        "            query_job = client.query(query)\n",
        "            results = query_job.result()\n",
        "            last_update = [row.last_update for row in results][0]\n",
        "\n",
        "            if last_update:\n",
        "                constraints = [{\"key\": \"Modified Date\", \"constraint_type\": \"greater than\", \"value\": last_update}]\n",
        "                print(f\"Última atualização encontrada: {last_update}. Aplicando constraints.\")\n",
        "                df_incremental = chamar_api_myfinance(url, headers, constraints)\n",
        "            else:\n",
        "                print(\"Nenhuma última atualização encontrada. Carregando todos os dados.\")\n",
        "                df_incremental = carregar_todos_os_dados(url, headers)\n",
        "\n",
        "            if not df_incremental.empty:\n",
        "                job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\", autodetect=True)\n",
        "                job = client.load_table_from_dataframe(df_incremental, table_id, job_config=job_config)\n",
        "                job.result()\n",
        "                print(f\"Total de registros inseridos com sucesso: {len(df_incremental)}\")\n",
        "                return f\"Total de registros inseridos com sucesso: {len(df_incremental)}\"\n",
        "            else:\n",
        "                print(\"Nenhum dado novo para inserir.\")\n",
        "                return \"Nenhum dado novo para inserir.\"\n",
        "        else:\n",
        "            # Carga completa inicial\n",
        "            df_inicial = carregar_todos_os_dados(url, headers)\n",
        "            job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\", autodetect=True)\n",
        "            job = client.load_table_from_dataframe(df_inicial, table_id, job_config=job_config)\n",
        "            job.result()\n",
        "            print(f\"Total de registros inseridos com sucesso: {len(df_inicial)}\")\n",
        "            return f\"Total de registros inseridos com sucesso: {len(df_inicial)}\"\n",
        "    else:\n",
        "        # Criação da tabela e carga completa inicial\n",
        "        df_inicial = carregar_todos_os_dados(url, headers)\n",
        "        job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\", autodetect=True)\n",
        "        job = client.load_table_from_dataframe(df_inicial, table_id, job_config=job_config)\n",
        "        job.result()\n",
        "        print(f\"Total de registros inseridos com sucesso: {len(df_inicial)}\")\n",
        "        return f\"Total de registros inseridos com sucesso: {len(df_inicial)}\""
      ],
      "metadata": {
        "id": "jiW5pH0pQix-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\": # Se o script for executado diretamente\n",
        "    main() # Chama a função principal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PFCp0w1Qi0E",
        "outputId": "8af6b05a-0b7d-463d-f409-cb7caebf9303"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando execução do script...\n",
            "Conectado ao serviço BigQuery.\n",
            "Dataset xfinance_dataset criado com sucesso.\n",
            "Tabela youtube-xfinance.xfinance_dataset.transactions não encontrada, será criada.\n",
            "Chamando API MyFinance...\n",
            "Total de registros inseridos com sucesso: 132\n"
          ]
        }
      ]
    }
  ]
}